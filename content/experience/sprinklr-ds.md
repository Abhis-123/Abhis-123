---
title: "Data Scientist"
description: "Sprinklr | India"
dateString: "June 2023 - Present"
draft: false
tags: ["LLM", "NLP", "MLOps", "Statistical Analysis", "Machine Learning", "Deep Learning", "Backend Development", "OOP", "Data Structures", "Algorithms", "Docker", "Jenkins", "MongoDB", "GCP", "Kubernetes", "Kafka", "Python", "C++", "SQL", "HTML", "CSS", "Git", "Pandas", "NumPy", "Matplotlib", "Scikit-Learn", "TensorFlow", "PyTorch", "Bootstrap", "Power Automate", "AutoCAD", "Fusion 360", "Cloud Computing", "Data Visualization", "DevOps", "APIs", "Agile Methodologies"]
showToc: false
weight: 303
---

### Description

- **Oversaw Full Lifecycle of Sentiment Analysis and Moderation Services:**  
  Directed the end-to-end training, testing, and deployment processes for sentiment analysis and content moderation tools. Implemented advanced modules for emotion detection and spam filtering, ensuring robust performance and reliable moderation in varied environments.

- **Fine-Tuned Advanced Language Models (LLMs) for Specialized Applications:**  
  Optimized large language models (LLMs) such as LLaMA3-8B, Phi3, LLaMA7B, and Mistral7B for task-specific roles in Generalized Classification and text analysis. Employed techniques like LoRA, QLoRA, and Supervised Fine-Tuning (SFT) to enhance model adaptability and precision in handling nuanced text processing tasks.

- **Innovated Prompting Techniques for Improved Instruction Adherence:**  
  Developed and integrated sophisticated prompting strategies—Chain of Thought (CoT), Buffer of Thought (BoT), and Retrieval-Augmented Generation (RAG)—to tackle instruction-following challenges in LLMs. These advancements resulted in models that better align with user requirements and maintain instructional consistency.

- **Implemented Optimization Techniques for Memory Efficiency and Speed:**  
  Applied advanced optimization methods, including pruning, quantization, efficient decoding, and prompt compression, reducing memory usage by 60-70% and doubling (2X) inference speed. This work significantly enhanced model performance in memory-constrained environments.

- **Curated Specialized Datasets for Improved Model Accuracy and Reliability:**  
  Developed domain-specific and task-oriented datasets for targeted model fine-tuning, enhancing instruction adherence and reducing hallucinations. These datasets enabled LLMs to perform more accurately within defined parameters, boosting reliability in real-world applications.
